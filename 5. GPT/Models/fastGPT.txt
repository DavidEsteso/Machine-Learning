0.910504 M parameters
step 0: train loss 3.7134, val loss 3.7128
step 100: train loss 0.9892, val loss 0.9911
step 200: train loss 0.4909, val loss 0.4925
step 300: train loss 0.4571, val loss 0.4589
step 400: train loss 0.4470, val loss 0.4499
step 500: train loss 0.4412, val loss 0.4440
step 600: train loss 0.4374, val loss 0.4392
step 700: train loss 0.4331, val loss 0.4366
step 800: train loss 0.4308, val loss 0.4329
step 900: train loss 0.4307, val loss 0.4348
step 999: train loss 0.4304, val loss 0.4324
training time: 156.4843487739563 seconds

He mp me please I wash hands
I hungry My teddy
I sing No touch
No like it Daddy read me dinosaur book before bed I dance
Yummy apple I tired
Look airplane No like it
Look moon like it
All done I want that I see bird
I see bird My teddy
I hungry More more
I want Go park
I see doggy Daddy read ce please
I jump high No like it
Bath time Yummy apple
I did it My teddy
I climb Where ball
Go park Big hug
I found it I wash hands
Dady play I hungry
No mine Where kitty go
I see bird No mine
I sing Bath ti

batch_size = 64 # how many independent sequences will we process in parallel?
block_size = 32 # what is the maximum context length for predictions?
max_iters = 1000
eval_interval = 100
learning_rate = 3e-4
device = 'cuda' if torch.cuda.is_available() else 'cpu'
eval_iters = 200
n_embd = 192
n_head = 2
n_layer = 2
dropout = 0.1